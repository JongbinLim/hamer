import torch

# ğŸ”¥ PyTorch ê¸°ë³¸ ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ê°•ì œ ì„¤ì •
torch.set_default_dtype(torch.float32)

# ğŸ”¥ TF32(ìë™ ì—°ì‚° ìµœì í™”)ë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ ì˜ˆê¸°ì¹˜ ì•Šì€ precision ë³€ê²½ ë°©ì§€
torch.backends.cuda.matmul.allow_tf32 = False
torch.backends.cudnn.allow_tf32 = False

# ğŸ”¥ GPU ìºì‹œ ì™„ì „ ì´ˆê¸°í™”
torch.cuda.empty_cache()
torch.cuda.reset_peak_memory_stats()

# ğŸ”¥ Autocastë¥¼ ë¬´ì¡°ê±´ Falseë¡œ ì„¤ì •í•˜ëŠ” ìƒˆë¡œìš´ ì»¨í…ìŠ¤íŠ¸ ì ìš©
with torch.cuda.amp.autocast(enabled=False):
    pass  # ì‹¤í–‰í•˜ì—¬ Autocastë¥¼ Falseë¡œ ê°•ì œ ë³€ê²½

# âœ… Autocast ìƒíƒœ í™•ì¸
print(f"Autocast status after reset: {torch.is_autocast_enabled()}")  # ğŸ”¥ ë°˜ë“œì‹œ Falseì—¬ì•¼ í•¨
